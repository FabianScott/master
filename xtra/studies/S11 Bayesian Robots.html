
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Bayesian Robots! &#8212; ML Engineering</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'xtra/studies/S11 Bayesian Robots';</script>
    <link rel="icon" href="../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/banner.jpeg" class="logo__image only-light" alt="ML Engineering - Home"/>
    <img src="../../_static/banner.jpeg" class="logo__image only-dark pst-js-only" alt="ML Engineering - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%200%20-%20Prerequisites.html">Prerequisites</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/01%20-%20Introduction.html">Lecture 1: Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/02%20-%20Linear%20Models.html">Lecture 2: Linear models</a></li>

<li class="toctree-l1"><a class="reference internal" href="../../notebooks/03%20-%20Kernelization.html">Lecture 3: Kernelization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/04%20-%20Model%20Selection.html">Lecture 4: Model Selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/05%20-%20Ensemble%20Learning.html">Lecture 5. Ensemble Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/06%20-%20Data%20Preprocessing.html">Lecture 6. Data preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/07%20-%20Bayesian%20Learning.html">Lecture 7. Bayesian Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/08%20-%20Neural%20Networks.html">Lecture 8. Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/09%20-%20Convolutional%20Neural%20Networks.html">Lecture 9: Convolutional Neural Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/10%20-%20Neural%20Networks%20for%20text.html">Lecture 10. Neural Networks for text</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Labs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%201a%20-%20Linear%20Models%20for%20Regression.html">Lab 1a: Linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%201b%20-%20Linear%20Models%20for%20Classification.html">Lab 1b: Linear classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%202a%20-%20Kernelization.html">Lab 2a: Kernelization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%202b%20-%20Model%20Selection.html">Lab 2b: Model selection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%203%20-%20Ensembles.html">Lab 3: Ensembles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%204%20-%20Pipelines.html">Lab 4:  Data preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%205%20-%20Bayesian%20learning.html">Lab 5: Bayesian models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%206%20-%20Neural%20Networks.html">Lab 6: Neural networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%207a%20-%20Convolutional%20Neural%20Networks.html">Lab 7a: Convolutional neural nets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%207b%20-%20Neural%20Networks%20for%20text.html">Lab 7b: Neural Networks for text</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/Tutorial%201%20-%20Python.html">Python for data analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/Tutorial%202%20-%20Python%20for%20Data%20Analysis.html">Python for scientific computing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notebooks/Tutorial%203%20-%20Machine%20Learning%20in%20Python.html">Machine Learning in Python</a></li>


<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%201%20-%20Tutorial.html">Lab 1: Machine Learning with Python</a></li>



<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%202%20-%20Tutorial.html">Lab 2: Model Selection in scikit-learn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%204%20-%20Tutorial.html">Lab 4: Data engineering pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%206%20-%20Tutorial.html">Lab 6: Deep Learning with TensorFlow</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../labs/Lab%207%20-%20Tutorial.html">Lab 7: Deep Learning for text</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/ml-course/master/blob/master/xtra/studies/S11 Bayesian Robots.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/ml-course/master" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/ml-course/master/issues/new?title=Issue%20on%20page%20%2Fxtra/studies/S11 Bayesian Robots.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/xtra/studies/S11 Bayesian Robots.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Bayesian Robots!</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#robot-navigation">Robot Navigation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-the-data">Visualizing the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-models">Classification models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-functions">Helper functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-data">Load the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-bayesian-optimization-60-points">1. Implementing Bayesian Optimization (60 points) {-}</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#class-to-perform-the-bayesian-optimization">Class to perform the Bayesian Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-samples">10 random samples</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#svm-classification">SVM Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#xg-boost-classification">XG Boost Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#xg-boost-regression">XG Boost Regression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#elasticnet-regression">ElasticNet Regression</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-3-iterations">Visualize 3 iterations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">SVM Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">XG Boost Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">XG Boost Regression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">ElasticNet Regression</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iterations">30 Iterations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">SVM Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#svm-optimal-hyperparameters">SVM optimal hyperparameters</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">XG Boost Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#xg-boost-classification-optimal-hyperparameters">XG Boost Classification optimal hyperparameters</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">XG Boost Regression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#xg-boost-regression-optimal-hyperparameters">XG Boost Regression optimal hyperparameters</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">ElasticNet Regression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#elasticnet-optimal-hyperparameters">ElasticNet optimal hyperparameters</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q1-discussion-interpretation">Q1: Discussion &amp; Interpretation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#note">Note</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#warm-starting-bayesian-optimization-20-points">2. Warm-starting Bayesian Optimization (20 points) {-}</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#best-hyperparameter-configurations">10 best hyperparameter configurations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">SVM Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">XG Boost Classification</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#randomly-remove-6-columns-from-the-dataset">Randomly remove 6 columns from the dataset</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#re-run-the-bayesian-optimization-starting-from-the-10-best-configurations-and-visualize-surrogate-model-at-initial-state">Re-run the Bayesian optimization, starting from the 10 best configurations and visualize surrogate model at initial state</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">SVM Classification</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">XG Boost Classification</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-surrogate-model-at-3-subsequent-iterations">Visualize the surrogate model at 3 subsequent iterations</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">SVM Classification</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#svm-warm-start-optimal-hyperparameters">SVM warm-start optimal hyperparameters</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">XG Boost Classification</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#xg-boost-classification-warm-start-optimal-hyperparameters">XG Boost classification warm-start optimal hyperparameters</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q2-discussion-interpretation">Q2: Discussion &amp; Interpretation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-processes-20-points">3. Gaussian Processes (20 points) {-}</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#guassian-process-with-xgbregressor">Guassian Process with XGBRegressor</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-10-random-samples">Visualize 10 random samples</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">Visualize 3 iterations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-30-iterations-with-a-gif">Visualize 30 iterations with a GIF</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-minimum-loss-over-30-iterations-with-xgbregressor-as-objective-model">Plot the minimum loss over 30 iterations with XGBRegressor as objective model</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#runtime-comparison-with-different-surrogate-models-for-xgbregressor-as-objective-model">Runtime comparison with different surrogate models for XGBRegressor as objective model</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-optimal-hyperparameters-for-xgbregressor-with-gaussianprocessregressor-vs-probrandomforestregressor">Compare optimal hyperparameters for XGBRegressor with GaussianProcessRegressor vs ProbRandomForestRegressor</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#guassian-process-with-elasticnet-regression">Guassian Process with ElasticNet Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">Visualize 10 random samples</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">Visualize 3 iterations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-30-iterations-with-gif">Visualize 30 iterations with GIF</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-loss-xgboost-regression-rfr-gp">Compare loss xgboost regression RFR &amp; GP</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-times-xgboost-regression-rfr-gp">Compare times xgboost regression RFR &amp; GP</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-optimal-hyperparameters-for-elasticnet-with-gaussianprocessregressor-vs-probrandomforestregressor">Compare optimal hyperparameters for ElasticNet with GaussianProcessRegressor vs ProbRandomForestRegressor</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q3-discussion-interpretation">Q3: Discussion &amp; Interpretation</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="bayesian-robots">
<h1>Bayesian Robots!<a class="headerlink" href="#bayesian-robots" title="Link to this heading">#</a></h1>
<p>We will use Bayesian optimization to efficiently tune machine learning algorithms for robot movement.</p>
<section id="robot-navigation">
<h2>Robot Navigation<a class="headerlink" href="#robot-navigation" title="Link to this heading">#</a></h2>
<p>The <a class="reference external" href="https://www.openml.org/d/1497">Wall robot navigation</a> contains training data for a robot equiped with ultrasound sensors. Based on 24 sensor readings, the robot has to figure out how to move though an office space without hitting walls or other obstacles. The possible actions (classes) are ‘Move-Forward’, ‘Slight-Right-Turn’, ‘Sharp-Right-Turn’, and ‘Slight-Left-Turn’.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># General imports</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span><span class="w"> </span><span class="nn">openml</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">oml</span>

<span class="c1"># Download Wall Robot Navigation data from OpenML.</span>
<span class="n">robotnav</span> <span class="o">=</span> <span class="n">oml</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">get_dataset</span><span class="p">(</span><span class="mi">1497</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cats</span><span class="p">,</span> <span class="n">attrs</span> <span class="o">=</span> <span class="n">robotnav</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="n">dataset_format</span><span class="o">=</span><span class="s1">&#39;array&#39;</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="n">robotnav</span><span class="o">.</span><span class="n">default_target_attribute</span><span class="p">)</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Move-Forward&#39;</span><span class="p">,</span><span class="s1">&#39;Slight-Right-Turn&#39;</span><span class="p">,</span><span class="s1">&#39;Sharp-Right-Turn&#39;</span><span class="p">,</span><span class="s1">&#39;Slight-Left-Turn&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualizing-the-data">
<h2>Visualizing the data<a class="headerlink" href="#visualizing-the-data" title="Link to this heading">#</a></h2>
<p>Let’s try to plot the position of the robot and where the walls are according to the sensors.
We can compute the coordinates of the detected wall using the angle of each sensor and basic
geometry:</p>
<p><span class="math notranslate nohighlight">\( x_{wall} = x_{robot} + dist * cos(angle_{robot} + angle_{sensor}) \)</span><br />
<span class="math notranslate nohighlight">\( y_{wall} = y_{robot} + dist * sin(angle_{robot} + angle_{sensor}) \)</span></p>
<p>Where <span class="math notranslate nohighlight">\(x_{robot}\)</span> is the x-coordinate of the robot, <span class="math notranslate nohighlight">\(dist\)</span> is the distance measured by the sensor,
<span class="math notranslate nohighlight">\(angle_{robot}\)</span> is the current direction the robot is facing and <span class="math notranslate nohighlight">\(angle_{sensor}\)</span> is the relative
angle of the specific sensor.</p>
<p>The dataset and the paper do not give any information on how fast the robot moves and how fast it
turns, so we have to guess these. It does say that it measures 9 samples per second. After some
trial and error we get plausible results if we set the speed to 0.1 meter per second and the turning
rate to about 2 degrees per second. Below is the resulting animation in which the robot is presented
as a triangle (green when moving and red when turning). The dots are the assumed locations of walls.
Although the visualization is probably not very precise, we can see that the robot follows the nearest wall.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">math</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.patches</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mpatches</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">colors</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib.animation</span><span class="w"> </span><span class="kn">import</span> <span class="n">FuncAnimation</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">HTML</span>
<span class="n">matplotlib</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;animation.embed_limit&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_tight_layout</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">cx</span><span class="p">,</span> <span class="n">cy</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span> <span class="c1"># robot position</span>
<span class="n">angle</span> <span class="o">=</span> <span class="mi">180</span>   <span class="c1"># robot direction</span>
<span class="n">ax</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
<span class="n">robot</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cx</span><span class="p">,</span><span class="n">cy</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">angle</span><span class="o">+</span><span class="mi">30</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="n">n</span><span class="p">):</span> 
    <span class="k">global</span> <span class="n">angle</span><span class="p">,</span> <span class="n">cx</span><span class="p">,</span> <span class="n">cy</span><span class="p">,</span> <span class="n">robot</span>
    <span class="n">curr_x</span><span class="p">,</span> <span class="n">cl</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">n</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">cl</span><span class="o">==</span><span class="mi">0</span><span class="p">:</span>
        <span class="n">cx</span><span class="o">+=</span><span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">radians</span><span class="p">(</span><span class="n">angle</span><span class="p">))</span><span class="o">*</span><span class="mf">0.012</span>
        <span class="n">cy</span><span class="o">+=</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">radians</span><span class="p">(</span><span class="n">angle</span><span class="p">))</span><span class="o">*</span><span class="mf">0.012</span>
    <span class="k">elif</span> <span class="n">cl</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">angle</span> <span class="o">-=</span> <span class="mf">0.02</span>
    <span class="k">elif</span> <span class="n">cl</span><span class="o">==</span><span class="mi">2</span><span class="p">:</span>
        <span class="n">angle</span> <span class="o">-=</span> <span class="mf">0.9</span>
    <span class="k">elif</span> <span class="n">cl</span><span class="o">==</span><span class="mi">3</span><span class="p">:</span>
        <span class="n">angle</span> <span class="o">+=</span> <span class="mf">0.02</span>
    <span class="k">if</span> <span class="n">n</span><span class="o">%</span><span class="k">30</span>==0: #speed things up by only plotting every n&#39;th step
        <span class="n">wall_points</span> <span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">cx</span><span class="o">+</span><span class="n">dist</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">radians</span><span class="p">(</span><span class="n">angle</span><span class="o">-</span><span class="mi">180</span><span class="o">+</span><span class="n">i</span><span class="o">*</span><span class="mi">15</span><span class="p">)),</span><span class="n">cy</span><span class="o">+</span><span class="n">dist</span><span class="o">*</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">radians</span><span class="p">(</span><span class="n">angle</span><span class="o">-</span><span class="mi">180</span><span class="o">+</span><span class="n">i</span><span class="o">*</span><span class="mi">15</span><span class="p">))]</span> 
                               <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">dist</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">curr_x</span><span class="p">)</span> <span class="k">if</span> <span class="n">dist</span><span class="o">&lt;</span><span class="mi">2</span> <span class="p">])</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
        <span class="c1">#robot.remove();</span>
        <span class="n">robot</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">cx</span><span class="p">,</span><span class="n">cy</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;g&#39;</span> <span class="k">if</span> <span class="n">cl</span><span class="o">==</span><span class="mi">0</span> <span class="k">else</span> <span class="s1">&#39;r&#39;</span><span class="p">),</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">angle</span><span class="o">+</span><span class="mi">30</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">wall_points</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">wall_points</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">anim</span> <span class="o">=</span> <span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5000</span><span class="p">),</span> <span class="n">interval</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">HTML</span><span class="p">(</span><span class="n">anim</span><span class="o">.</span><span class="n">to_jshtml</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="classification-models">
<h2>Classification models<a class="headerlink" href="#classification-models" title="Link to this heading">#</a></h2>
<p>We try the following models (for simplicity, we will only tune the 2 most important hyperparameters per model):</p>
<ul class="simple">
<li><p>Support vector machine, with hyperparameters <span class="math notranslate nohighlight">\(C \in [10^{-12},10^{12}]\)</span>, <span class="math notranslate nohighlight">\(\gamma \in [10^{-12},10^{12}]\)</span> (both log scale), and an RBF kernel.</p></li>
<li><p>Gradient Boosting, with hyperparameters <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> <span class="math notranslate nohighlight">\(\in [10^{-4},10^{-1}]\)</span> (log scale), <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> <span class="math notranslate nohighlight">\(\in [1,5]\)</span>, and <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> fixed at least 1000 (you can increase this if your computing resources allow).</p></li>
</ul>
<p>We want a fast way to optimize and re-optimize the model so that it will keep working well. We will use Bayesian optimization for this.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.ticker</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">mtick</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">imageio</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">io</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">itertools</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">time</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">mpl_toolkits</span><span class="w"> </span><span class="kn">import</span> <span class="n">mplot3d</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">random</span><span class="w"> </span><span class="kn">import</span> <span class="n">randint</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">colors</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.ensemble</span><span class="w"> </span><span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.linear_model</span><span class="w"> </span><span class="kn">import</span> <span class="n">ElasticNet</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.svm</span><span class="w"> </span><span class="kn">import</span> <span class="n">SVC</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">xgboost.sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">XGBModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">xgboost</span><span class="w"> </span><span class="kn">import</span> <span class="n">XGBClassifier</span><span class="p">,</span> <span class="n">XGBRegressor</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.gaussian_process</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">RuntimeWarning</span><span class="p">)</span> 

<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Random Forest that also returns the standard deviation of predictions</span>
<span class="k">class</span><span class="w"> </span><span class="nc">ProbRandomForestRegressor</span><span class="p">(</span><span class="n">RandomForestRegressor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A Random Forest regressor that can also returns the standard deviations for all predictions</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>       
        <span class="n">preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">estimators_</span><span class="p">:</span>
            <span class="n">preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">return_std</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Helper function to compute expected improvement </span>
<span class="k">def</span><span class="w"> </span><span class="nf">EI</span><span class="p">(</span><span class="n">surrogate</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">curr_best</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">balance</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes the Expected Improvement</span>
<span class="sd">    surrogate, The surrogate model</span>
<span class="sd">    X: np.ndarray(N, D), The input points where the acquisition function</span>
<span class="sd">        should be evaluated. N configurations with D hyperparameters</span>
<span class="sd">    curr_best, The current best performance</span>
<span class="sd">    balance, Decrease to focus more on exploration, increase to focus on exploitation (optional)</span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    np.ndarray(N,1), Expected Improvement of X</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

    <span class="n">m</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">surrogate</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># mean, stdev</span>

    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">curr_best</span> <span class="o">-</span> <span class="n">m</span> <span class="o">-</span> <span class="n">balance</span><span class="p">)</span> <span class="o">/</span> <span class="n">s</span>
    <span class="n">f</span> <span class="o">=</span> <span class="p">(</span><span class="n">curr_best</span> <span class="o">-</span> <span class="n">m</span> <span class="o">-</span> <span class="n">balance</span><span class="p">)</span> <span class="o">*</span> <span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="o">+</span> <span class="n">s</span> <span class="o">*</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">s</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">):</span> <span class="c1"># uncertainty should never be exactly 0.0</span>
        <span class="n">f</span><span class="p">[</span><span class="n">s</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">return</span> <span class="n">f</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="load-the-data">
<h2>Load the data<a class="headerlink" href="#load-the-data" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Fetch classification data</span>
<span class="n">robotnav</span> <span class="o">=</span> <span class="n">oml</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">get_dataset</span><span class="p">(</span><span class="mi">1497</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">robotnav</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="n">dataset_format</span><span class="o">=</span><span class="s1">&#39;array&#39;</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="n">robotnav</span><span class="o">.</span><span class="n">default_target_attribute</span><span class="p">)</span>

<span class="c1"># Fetch regression data</span>
<span class="n">robotarm</span> <span class="o">=</span> <span class="n">oml</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">get_dataset</span><span class="p">(</span><span class="mi">189</span><span class="p">)</span>
<span class="n">Xr</span><span class="p">,</span> <span class="n">yr</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">robotarm</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="n">dataset_format</span><span class="o">=</span><span class="s1">&#39;dataframe&#39;</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="n">robotarm</span><span class="o">.</span><span class="n">default_target_attribute</span><span class="p">)</span>

<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Xr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">yr</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="implementing-bayesian-optimization-60-points">
<h2>1. Implementing Bayesian Optimization (60 points) {-}<a class="headerlink" href="#implementing-bayesian-optimization-60-points" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Implement Bayesian optimization using the code above and use it to optimize the hyperparameters stated below for each of the two datasets.</p>
<ul>
<li><p>Use the hyperparameters and ranges are defined above. Make sure to sample from a log scale (<code class="docutils literal notranslate"><span class="pre">numpy.logspace</span></code>) whenever the hyperparameters should be varied on a log scale.</p></li>
<li><p>The evaluation measure for classification should be misclassification error (1 - Accuracy), evaluated using 3-fold cross-validation</p></li>
<li><p>The evaluation measure for regression should be mean squared error, also evaluated using 3-fold cross-validation</p></li>
</ul>
</li>
<li><p>Initialize the surrogate model with 10 randomly sampled configurations and visualize the surrogate model.</p>
<ul>
<li><p>Hint: Use a 2D slice of each hyperparameter (e.g. <span class="math notranslate nohighlight">\(C\)</span>=4 and <span class="math notranslate nohighlight">\(\gamma\)</span>=0.1) to show both the predicted values and the uncertainty.</p></li>
<li><p>For simplicity, you can build a separate surrogate model for each algorithm and each dataset (4 models in total)</p></li>
</ul>
</li>
<li><p>Visualize the resulting acquisition function, either as 2D slices (or, more difficult, as a 3D surface)</p></li>
<li><p>Visualize 3 more iterations, each time visualizing the surrogate model and acquisition function</p></li>
<li><p>Run the Bayesian optimization for at least 30 iterations, report the optimal configuration and show the final surrogate model (2D slices or 3D surface).</p></li>
<li><p>Interpret and explain the results. Does Bayesian optimization efficiently find good configurations? Do you notice any
differences between the different models and the different datasets. Explain the results as well as you can.</p></li>
</ul>
<section id="class-to-perform-the-bayesian-optimization">
<h3>Class to perform the Bayesian Optimization<a class="headerlink" href="#class-to-perform-the-bayesian-optimization" title="Link to this heading">#</a></h3>
<p>You can supply your own surrogate and objective function to the model. The hyperparameter combinations we would like to run on the objective model are stored in <code class="docutils literal notranslate"><span class="pre">self.hyperparam_obj</span></code>. After the objective model calculated the losses we create a grid of 30 by 30 of all hyperparameter combinations. This is stored in <code class="docutils literal notranslate"><span class="pre">self.hyperparams_sur</span></code>. Afterwards we predict the loss for all these values and create a 3D plot to show the surrogate model and acquisition function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">BayesianOptimization</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
               <span class="n">surrogate_model</span><span class="p">,</span> 
               <span class="n">objective_model</span><span class="p">,</span> 
               <span class="n">acquisition_function</span><span class="p">,</span>
               <span class="n">hyperparam_space</span><span class="p">,</span>
               <span class="n">X_obj</span><span class="p">,</span>
               <span class="n">y_obj</span><span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">surrogate_model</span> <span class="o">=</span> <span class="n">surrogate_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective_model</span> <span class="o">=</span> <span class="n">objective_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span> <span class="o">=</span> <span class="p">[</span><span class="o">*</span><span class="n">hyperparam_space</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_space</span> <span class="o">=</span> <span class="n">hyperparam_space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_function</span> <span class="o">=</span> <span class="n">acquisition_function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_obj</span><span class="o">=</span><span class="n">X_obj</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y_obj</span><span class="o">=</span><span class="n">y_obj</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">highest_EI</span><span class="o">=</span><span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">objective_model</span><span class="p">())</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">surrogate_model_name</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">surrogate_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_surrogate</span><span class="o">=</span><span class="p">[]</span>

        <span class="c1"># Dataframe to store all hyperparameters and their predictions</span>
        <span class="c1"># of the objective function</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
          <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">])</span>

        <span class="c1"># Dataframe to store all hyperparameters and their predictions</span>
        <span class="c1"># of the surrogate model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
          <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">,</span> <span class="s1">&#39;pred&#39;</span><span class="p">,</span> <span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="s1">&#39;improvement&#39;</span><span class="p">])</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">optimal_hyperparams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rows</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns dataframe with the optimal hyperparameters and the corresponding loss score. </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)[:</span><span class="n">rows</span><span class="p">]</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">hyperparam_points</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hyperparam_name</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">unique</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a population for a certain hyperparameter</span>
<span class="sd">        (E.g. 1000 log spaced points to sample from)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get the required settings</span>
        <span class="n">settings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_space</span><span class="p">[</span><span class="n">hyperparam_name</span><span class="p">]</span>
        
        <span class="c1"># Log spaced</span>
        <span class="k">if</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;spacing&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;log&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">settings</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">],</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">],</span> <span class="n">size</span><span class="p">)</span>
        
        <span class="c1"># Linear spaced</span>
        <span class="k">if</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;spacing&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;lin&#39;</span><span class="p">:</span>
            <span class="c1"># Only unique values (E.g. 1,2,3,4,5)</span>
            <span class="k">if</span> <span class="n">unique</span> <span class="ow">and</span> <span class="n">discrete</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">settings</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">],</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
            
            <span class="c1"># Only discrete values (E.g. 1,1,1,1,1,1,2,2,2,2,2)</span>
            <span class="k">if</span> <span class="n">discrete</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">settings</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">],</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">],</span> <span class="n">size</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
            
            <span class="c1"># Continues values (E.g. 1.0, 1.1, 1.2, 1.3, 1.4)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">settings</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">],</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">],</span> <span class="n">size</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">hyperparam_cartesian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a grid of the two hyperparameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">points</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">hyperparam_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">:</span>
            <span class="n">settings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_space</span><span class="p">[</span><span class="n">hyperparam_name</span><span class="p">]</span>
            
            <span class="c1"># Check if the sampling needs to be discrete</span>
            <span class="n">discrete</span> <span class="o">=</span> <span class="p">((</span><span class="n">settings</span><span class="p">[</span><span class="s1">&#39;spacing&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;lin&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;discrete&#39;</span><span class="p">])</span>
            
            <span class="c1"># Get the population of points</span>
            <span class="n">points</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_points</span><span class="p">(</span><span class="n">hyperparam_name</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">unique</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="n">discrete</span><span class="p">))</span>

        <span class="c1"># Create the cartesian product of the two hyperparams</span>
        <span class="n">cartesian</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="o">*</span><span class="n">points</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Store the values</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">hyperparam_name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">):</span>
                
            <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span><span class="p">[</span><span class="n">hyperparam_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">cartesian</span><span class="p">[:,</span><span class="n">idx</span><span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span>
      
    <span class="k">def</span><span class="w"> </span><span class="nf">hyperparam_sampling</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create the initial hyperparameter samples to start the optimization.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">hyperparam_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">:</span>
            <span class="n">settings</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_space</span><span class="p">[</span><span class="n">hyperparam_name</span><span class="p">]</span>
            
            <span class="c1"># Check if the sampling needs to be discrete</span>
            <span class="n">discrete</span> <span class="o">=</span> <span class="p">((</span><span class="n">settings</span><span class="p">[</span><span class="s1">&#39;spacing&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;lin&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;discrete&#39;</span><span class="p">])</span>
            
            <span class="c1"># Get the population of points</span>
            <span class="n">points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_points</span><span class="p">(</span><span class="n">hyperparam_name</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="n">discrete</span><span class="p">)</span>

            <span class="c1"># Take n samples from the population</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="n">points</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)]</span>

            <span class="c1"># Store the results</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="n">hyperparam_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">sample</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span>
    
    <span class="k">def</span><span class="w"> </span>
<span class="w">    </span>
<span class="w">    </span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">static_hyperparams</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict all the hyperparameter combinations that do not have a prediction yet</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">hyperparams</span> <span class="ow">in</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()]</span>
                                 <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                                 <span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
                                 <span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            
            <span class="c1"># Setup the classifier</span>
            <span class="n">clf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_model</span><span class="p">(</span><span class="o">**</span><span class="n">hyperparams</span><span class="p">,</span> <span class="o">**</span><span class="n">static_hyperparams</span><span class="p">)</span>

            <span class="c1"># Get the mean accuracy over all three folds</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_obj</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_obj</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> 
                                       <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>

            <span class="c1"># Calculate the mean 1 - acc loss</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>

            <span class="c1"># Store the loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span>
      
    <span class="k">def</span><span class="w"> </span><span class="nf">regressor_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">static_hyperparams</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict all the hyperparameter combinations that do not have a prediction yet</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">hyperparams</span> <span class="ow">in</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">isnull</span><span class="p">()]</span>
                                 <span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                                 <span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
                                 <span class="o">.</span><span class="n">items</span><span class="p">()):</span>
            
            <span class="c1"># Setup the classifier</span>
            <span class="n">clf</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective_model</span><span class="p">(</span><span class="o">**</span><span class="n">hyperparams</span><span class="p">,</span> <span class="o">**</span><span class="n">static_hyperparams</span><span class="p">)</span>

            <span class="c1"># Get the mean accuracy over all three folds</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_obj</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y_obj</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> 
                                       <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;neg_mean_squared_error&quot;</span><span class="p">)</span>

            <span class="c1"># Calculate </span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

            <span class="c1"># Store the loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span>
      
    <span class="k">def</span><span class="w"> </span><span class="nf">surrogate_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">static_hyperparams</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict all the hyperparameter combinations using the surrogate model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The train set will be the hyperparameters that have been</span>
        <span class="c1"># predicted by the objective model</span>
        <span class="n">X_sur</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">)]</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">)]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
        
        <span class="c1"># Record the start time</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        
        <span class="c1"># Fit the model on the objective model losses</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">surrogate_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

        <span class="c1"># Predict all points using the surrogate model</span>
        <span class="n">y_pred</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">surrogate_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
          <span class="n">X_sur</span><span class="p">,</span> 
          <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="c1"># Record the end time</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">time_surrogate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">end</span><span class="o">-</span><span class="n">start</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s1">&#39;pred&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s1">&#39;sigma&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">sigma</span>

        <span class="c1"># Calculate the expected improvement</span>
        <span class="n">expected_improvement</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">acquisition_function</span><span class="p">(</span>
          <span class="bp">self</span><span class="o">.</span><span class="n">surrogate_model</span><span class="p">,</span> 
          <span class="n">X_sur</span><span class="p">)</span>
        
        <span class="c1"># Store the max expected improvement for creating the graphs</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">expected_improvement</span><span class="p">)</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">highest_EI</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">highest_EI</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">expected_improvement</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="s1">&#39;improvement&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">expected_improvement</span>
  
    <span class="k">def</span><span class="w"> </span><span class="nf">next_sample</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function that picks the next best hyperparameters to look at</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get the index of the hyperparameters that show the highest expected improvement</span>
        <span class="c1"># We shuffle the dataframe to prevent it from picking the same values over and over again</span>
        <span class="n">parameters_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span><span class="p">[</span><span class="s1">&#39;improvement&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()</span>

        <span class="c1"># Get the values of hyperparameters associated with highest expected improvement</span>
        <span class="n">opt_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">parameters_idx</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">)]</span>

        <span class="c1"># Add it to the objective model hyperparameters to be predicted in the next run</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">opt_params</span><span class="p">,</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
        <span class="c1"># Change the data types to fix a bug with XGBoost</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">force_dtypes</span><span class="p">()</span>
  
    <span class="k">def</span><span class="w"> </span><span class="nf">force_dtypes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Helper fucntion to cast the column of the hyperparams objective function to the right types</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">hyperparam_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">:</span>
            <span class="n">setting</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_space</span><span class="p">[</span><span class="n">hyperparam_name</span><span class="p">]</span>
            
            <span class="k">if</span> <span class="p">(</span><span class="n">setting</span><span class="p">[</span><span class="s1">&#39;spacing&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;lin&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">setting</span><span class="p">[</span><span class="s1">&#39;discrete&#39;</span><span class="p">]:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="n">hyperparam_name</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="n">hyperparam_name</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_surrogate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">show_confidence</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">show_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to create a 3d plot of the surrogate model and the acquisition </span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Create the two figures</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
        <span class="n">ax_sur</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
        <span class="n">ax_acq</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>

        <span class="c1"># Get the z values</span>
        <span class="n">z_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span>
        <span class="n">z_loss_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.03</span>
        <span class="n">z_acq</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span><span class="p">[</span><span class="s1">&#39;improvement&#39;</span><span class="p">]</span>

        <span class="n">first_param</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_space</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">second_param</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_space</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>

        <span class="n">x_plot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">y_plot</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>

        <span class="n">x_plot_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
        <span class="n">y_plot_obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>

        <span class="c1"># Space the points logaritmic if necessary</span>
        <span class="k">if</span> <span class="n">first_param</span><span class="p">[</span><span class="s1">&#39;spacing&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;log&#39;</span><span class="p">:</span>
            <span class="n">x_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">x_plot</span><span class="p">)</span>
            <span class="n">x_plot_obj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">x_plot_obj</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">second_param</span><span class="p">[</span><span class="s1">&#39;spacing&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;log&#39;</span><span class="p">:</span>
            <span class="n">y_plot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">y_plot</span><span class="p">)</span>
            <span class="n">y_plot_obj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">y_plot_obj</span><span class="p">)</span>

        <span class="c1"># The maximum loss of the surrogate function</span>
        <span class="n">loss_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_sur</span><span class="p">[</span><span class="s1">&#39;pred&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
        <span class="n">loss_max</span> <span class="o">+=</span> <span class="p">(</span><span class="n">loss_max</span> <span class="o">*</span> <span class="mf">0.1</span><span class="p">)</span>

        <span class="c1"># Show the plots</span>
        <span class="n">ax_sur</span><span class="o">.</span><span class="n">plot_trisurf</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span> <span class="n">y_plot</span><span class="p">,</span> <span class="n">z_loss</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;plasma&#39;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_plot_obj</span><span class="p">)):</span>
            <span class="n">first_hyperparam</span> <span class="o">=</span> <span class="n">x_plot_obj</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
            <span class="n">second_hyperparam</span> <span class="o">=</span> <span class="n">y_plot_obj</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">z_loss_obj</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>

            <span class="n">ax_sur</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                <span class="p">[</span><span class="n">first_hyperparam</span><span class="p">,</span><span class="n">first_hyperparam</span><span class="p">],</span>
                <span class="p">[</span><span class="n">second_hyperparam</span><span class="p">,</span><span class="n">second_hyperparam</span><span class="p">],</span>
                <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="n">loss_max</span><span class="o">*</span><span class="mf">0.05</span><span class="p">],</span>
                <span class="n">color</span> <span class="o">=</span> <span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">ax_acq</span><span class="o">.</span><span class="n">plot_trisurf</span><span class="p">(</span><span class="n">x_plot</span><span class="p">,</span> <span class="n">y_plot</span><span class="p">,</span> <span class="n">z_acq</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;plasma&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">first_param</span><span class="p">[</span><span class="s1">&#39;spacing&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;log&#39;</span><span class="p">:</span>
            <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span> <span class="o">=</span> <span class="n">first_param</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">],</span> <span class="n">first_param</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">]</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span><span class="nb">max</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="nb">min</span><span class="p">,</span><span class="nb">max</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
            <span class="n">ax_sur</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">mtick</span><span class="o">.</span><span class="n">FormatStrFormatter</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%.2e</span><span class="s1">&#39;</span><span class="p">))</span>
            <span class="n">ax_acq</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_major_formatter</span><span class="p">(</span><span class="n">mtick</span><span class="o">.</span><span class="n">FormatStrFormatter</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%.2e</span><span class="s1">&#39;</span><span class="p">))</span>

        <span class="n">ax_sur</span><span class="o">.</span><span class="n">set_zlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">loss_max</span><span class="p">)</span>
        <span class="n">ax_acq</span><span class="o">.</span><span class="n">set_zlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">highest_EI</span><span class="p">)</span>

        <span class="c1"># Labels</span>
        <span class="n">ax_sur</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Hyper-parameter loss function for </span><span class="si">{}</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span> <span class="n">label</span><span class="p">),</span> <span class="n">pad</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
        <span class="n">ax_acq</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Hyper-parameter expected improvement function for </span><span class="si">{}</span><span class="s1"> </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span> <span class="n">label</span><span class="p">),</span> <span class="n">pad</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>

        <span class="n">ax_sur</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">ax_sur</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">ax_sur</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">ax_acq</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">ax_acq</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparam_names</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">ax_acq</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">&#39;Expected Improvement&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

        <span class="c1"># Give the axis labels a bit more space</span>
        <span class="n">ax_sur</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">labelpad</span><span class="p">,</span> <span class="n">ax_sur</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">labelpad</span><span class="p">,</span> <span class="n">ax_sur</span><span class="o">.</span><span class="n">zaxis</span><span class="o">.</span><span class="n">labelpad</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span>
        <span class="n">ax_acq</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">labelpad</span><span class="p">,</span> <span class="n">ax_acq</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">labelpad</span><span class="p">,</span> <span class="n">ax_acq</span><span class="o">.</span><span class="n">zaxis</span><span class="o">.</span><span class="n">labelpad</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span>

        <span class="c1"># Alter font sizes</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">14</span><span class="p">})</span>
        <span class="n">ax_sur</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">ax_sur</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
        <span class="n">ax_acq</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;major&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">ax_acq</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;minor&#39;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">store_plot</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;.gif_images/</span><span class="si">{}</span><span class="s1">_it_</span><span class="si">{}</span><span class="s1">.png&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">)))</span>
        <span class="k">if</span> <span class="n">show_plot</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
            
    <span class="k">def</span><span class="w"> </span><span class="nf">generate_gif</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to generate a gif based on the loss plots of the model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">png_dir</span> <span class="o">=</span> <span class="s1">&#39;.gif_images/&#39;</span>
        <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">file_name</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">png_dir</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">file_name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">):</span>
                <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">png_dir</span><span class="p">,</span> <span class="n">file_name</span><span class="p">)</span>
                <span class="n">images</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">file_path</span><span class="p">))</span>
                <span class="n">gif_filename</span> <span class="o">=</span> <span class="s1">&#39;</span><span class="si">{}{}</span><span class="s1">.gif&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">png_dir</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">)</span>
                <span class="n">io</span><span class="o">.</span><span class="n">mimsave</span><span class="p">(</span><span class="n">gif_filename</span><span class="p">,</span> <span class="n">images</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>
                
        <span class="k">return</span> <span class="n">Image</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="n">gif_filename</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plots the minimum loss over 30 iterations</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># List for the lowest loss score observed per iteration</span>
        <span class="n">min_points</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Appends the lowest loss from the initial 10 samples</span>
        <span class="n">min_points</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[:</span><span class="mi">10</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">]))</span>

        <span class="c1"># Iteratively appends the lowest loss</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[</span><span class="mi">10</span><span class="p">:])):</span>
            <span class="n">min_points</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hyperparams_obj</span><span class="p">[:</span><span class="n">iteration</span><span class="o">+</span><span class="mi">11</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">]))</span>
        
        <span class="c1"># Lowest loss score overall</span>
        <span class="n">min_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">min_points</span><span class="p">)</span>
        
        <span class="c1"># Show plot of minimum loss over the iterations</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>

        <span class="n">textstr</span> <span class="o">=</span> <span class="s1">&#39;minimum loss = </span><span class="si">{:.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">min_loss</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">min_points</span><span class="p">)),</span> <span class="n">min_points</span><span class="p">,</span> <span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">min_points</span><span class="p">)),</span> <span class="n">min_points</span><span class="p">,</span> <span class="s1">&#39;bo&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Minimum loss over 30 iterations for </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_name</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Iterations&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Loss&#39;</span><span class="p">)</span>

        <span class="n">props</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">boxstyle</span><span class="o">=</span><span class="s1">&#39;round&#39;</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;wheat&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="n">textstr</span> <span class="o">=</span> <span class="s1">&#39;minimum loss = </span><span class="si">{:.5f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">min_loss</span><span class="p">)</span>

        <span class="c1"># place a text box in upper right in axes coords</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="n">textstr</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span>
                <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;top&#39;</span><span class="p">,</span> <span class="n">bbox</span><span class="o">=</span><span class="n">props</span><span class="p">)</span> 

        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="random-samples">
<h3>10 random samples<a class="headerlink" href="#random-samples" title="Link to this heading">#</a></h3>
<section id="svm-classification">
<h4>SVM Classification<a class="headerlink" href="#svm-classification" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">settings</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">],</span> <span class="n">settings</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">],</span> <span class="n">size</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">initialize</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">()</span>
    


<span class="k">def</span><span class="w"> </span><span class="nf">update</span><span class="p">(</span><span class="n">n</span><span class="p">):</span> 
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">wall_points</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span><span class="n">wall_points</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">anim</span> <span class="o">=</span> <span class="n">FuncAnimation</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">frames</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span> <span class="n">interval</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">HTML</span><span class="p">(</span><span class="n">anim</span><span class="o">.</span><span class="n">to_jshtml</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hyperparam_space</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="mf">2.0</span><span class="p">),</span>
  <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">base</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
<span class="p">}</span>

<span class="nb">print</span><span class="p">(</span><span class="n">hyperparam_space</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="mi">10</span><span class="p">])</span>

<span class="n">svm</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
  <span class="n">surrogate_model</span><span class="o">=</span><span class="n">ProbRandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
  <span class="n">objective_model</span><span class="o">=</span><span class="n">SVC</span><span class="p">,</span>
  <span class="n">acquisition_function</span><span class="o">=</span><span class="n">EI</span><span class="p">,</span>
  <span class="n">hyperparam_space</span><span class="o">=</span><span class="n">hyperparam_space</span><span class="p">,</span>
  <span class="n">X_obj</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
  <span class="n">y_obj</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="n">svm</span><span class="o">.</span><span class="n">hyperparam_sampling</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">svm</span><span class="o">.</span><span class="n">hyperparam_cartesian</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>

<span class="n">svm</span><span class="o">.</span>

<span class="p">()</span>
<span class="n">svm</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>

<span class="n">svm</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(10 Samples)&#39;</span><span class="p">,</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hyperparam_space</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">1000</span><span class="p">),</span>
  <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="p">}</span>            

<span class="n">metadata</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="o">*</span><span class="n">hyperparam_space</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="s1">&#39;loss&#39;</span><span class="p">,</span> <span class="s1">&#39;pred&#39;</span><span class="p">,</span> <span class="s1">&#39;sigma&#39;</span><span class="p">,</span> <span class="s1">&#39;EI&#39;</span><span class="p">])</span>
<span class="k">for</span> <span class="n">hp</span> <span class="ow">in</span> <span class="n">hyperparam_space</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">metadata</span><span class="p">[</span><span class="n">hp</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">hyperparam_space</span><span class="p">[</span><span class="n">hp</span><span class="p">],</span><span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">metadata</span><span class="p">[</span><span class="n">hyperparam_space</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">metadata</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="o">**</span><span class="n">metadata</span><span class="p">[</span><span class="n">hyperparam_space</span><span class="o">.</span><span class="n">keys</span><span class="p">()]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
    <span class="n">metadata</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>

<span class="n">metadata</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample</span> <span class="o">=</span> <span class="n">points</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<p>The black bars indicate the hyperparameter configurations where the objective model was tested.</p>
</section>
<section id="xg-boost-classification">
<h4>XG Boost Classification<a class="headerlink" href="#xg-boost-classification" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgclas_param_template</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;spacing&#39;</span><span class="p">:</span> <span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;discrete&#39;</span><span class="p">:</span> <span class="kc">False</span> <span class="p">},</span>
  <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;spacing&#39;</span><span class="p">:</span> <span class="s1">&#39;lin&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;discrete&#39;</span><span class="p">:</span> <span class="kc">True</span> <span class="p">}</span>
<span class="p">}</span>

<span class="n">xgclas</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
  <span class="n">surrogate_model</span><span class="o">=</span><span class="n">ProbRandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
  <span class="n">objective_model</span><span class="o">=</span><span class="n">XGBClassifier</span><span class="p">,</span>
  <span class="n">acquisition_function</span><span class="o">=</span><span class="n">EI</span><span class="p">,</span>
  <span class="n">hyperparam_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">),</span>
  <span class="n">hyperparam_space</span><span class="o">=</span><span class="n">xgclas_param_template</span><span class="p">,</span>
  <span class="n">X_obj</span><span class="o">=</span><span class="n">X</span><span class="p">,</span>
  <span class="n">y_obj</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="n">xgclas</span><span class="o">.</span><span class="n">hyperparam_sampling</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">xgclas</span><span class="o">.</span><span class="n">hyperparam_cartesian</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>

<span class="n">xgclas</span><span class="o">.</span><span class="n">classifier_predict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xgclas</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>

<span class="n">xgclas</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;(10 Samples)&#39;</span><span class="p">,</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="xg-boost-regression">
<h4>XG Boost Regression<a class="headerlink" href="#xg-boost-regression" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgreg_param_template</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;spacing&#39;</span><span class="p">:</span> <span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;discrete&#39;</span><span class="p">:</span> <span class="kc">False</span> <span class="p">},</span>
  <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;spacing&#39;</span><span class="p">:</span> <span class="s1">&#39;lin&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">&#39;discrete&#39;</span><span class="p">:</span> <span class="kc">True</span> <span class="p">}</span>
<span class="p">}</span>

<span class="n">xgreg</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
  <span class="n">surrogate_model</span><span class="o">=</span><span class="n">ProbRandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
  <span class="n">objective_model</span><span class="o">=</span><span class="n">XGBRegressor</span><span class="p">,</span>
    
  <span class="n">acquisition_function</span><span class="o">=</span><span class="n">EI</span><span class="p">,</span>
  <span class="n">hyperparam_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">),</span>
  <span class="n">hyperparam_space</span><span class="o">=</span><span class="n">xgreg_param_template</span><span class="p">,</span>
  <span class="n">X_obj</span><span class="o">=</span><span class="n">Xr</span><span class="p">,</span>
  <span class="n">y_obj</span><span class="o">=</span><span class="n">yr</span>
<span class="p">)</span>

<span class="n">xgreg</span><span class="o">.</span><span class="n">hyperparam_sampling</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">xgreg</span><span class="o">.</span><span class="n">hyperparam_cartesian</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>

<span class="n">xgreg</span><span class="o">.</span><span class="n">regressor_predict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xgreg</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>

<span class="n">xgreg</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;(10 Samples)&#39;</span><span class="p">,</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="elasticnet-regression">
<h4>ElasticNet Regression<a class="headerlink" href="#elasticnet-regression" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elas_param_template</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;spacing&#39;</span><span class="p">:</span> <span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">12</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span> <span class="mi">12</span><span class="p">,</span> <span class="s1">&#39;discrete&#39;</span><span class="p">:</span> <span class="kc">False</span> <span class="p">},</span>
  <span class="s1">&#39;l1_ratio&#39;</span><span class="p">:</span> <span class="p">{</span> <span class="s1">&#39;spacing&#39;</span><span class="p">:</span> <span class="s1">&#39;lin&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;discrete&#39;</span><span class="p">:</span> <span class="kc">False</span> <span class="p">}</span>
<span class="p">}</span>

<span class="n">elas</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
  <span class="n">surrogate_model</span><span class="o">=</span><span class="n">ProbRandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
  <span class="n">objective_model</span><span class="o">=</span><span class="n">ElasticNet</span><span class="p">,</span>
  <span class="n">acquisition_function</span><span class="o">=</span><span class="n">EI</span><span class="p">,</span>
  <span class="n">hyperparam_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;l1_ratio&#39;</span><span class="p">),</span>
  <span class="n">hyperparam_space</span><span class="o">=</span><span class="n">elas_param_template</span><span class="p">,</span>
  <span class="n">X_obj</span><span class="o">=</span><span class="n">Xr</span><span class="p">,</span>
  <span class="n">y_obj</span><span class="o">=</span><span class="n">yr</span>
<span class="p">)</span>

<span class="n">elas</span><span class="o">.</span><span class="n">hyperparam_sampling</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">elas</span><span class="o">.</span><span class="n">hyperparam_cartesian</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>

<span class="n">elas</span><span class="o">.</span><span class="n">regressor_predict</span><span class="p">()</span>
<span class="n">elas</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>

<span class="n">elas</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;(10 Samples)&#39;</span><span class="p">,</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Visualize 3 more iterations, each time visualizing the surrogate model and acquisition function</p>
</section>
</section>
<section id="visualize-3-iterations">
<h3>Visualize 3 iterations<a class="headerlink" href="#visualize-3-iterations" title="Link to this heading">#</a></h3>
<section id="id1">
<h4>SVM Classification<a class="headerlink" href="#id1" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">classifier_predict</span><span class="p">()</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">2</span><span class="p">),</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h4>XG Boost Classification<a class="headerlink" href="#id2" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgclas</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">xgclas</span><span class="o">.</span><span class="n">classifier_predict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xgclas</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">xgclas</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">2</span><span class="p">),</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">xgclas</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id3">
<h4>XG Boost Regression<a class="headerlink" href="#id3" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgreg</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">xgreg</span><span class="o">.</span><span class="n">regressor_predict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xgreg</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">xgreg</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">2</span><span class="p">),</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">xgreg</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id4">
<h4>ElasticNet Regression<a class="headerlink" href="#id4" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elas</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">elas</span><span class="o">.</span><span class="n">regressor_predict</span><span class="p">()</span>
    <span class="n">elas</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">elas</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">2</span><span class="p">),</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">elas</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="iterations">
<h3>30 Iterations<a class="headerlink" href="#iterations" title="Link to this heading">#</a></h3>
<section id="id5">
<h4>SVM Classification<a class="headerlink" href="#id5" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">27</span><span class="p">):</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">classifier_predict</span><span class="p">()</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
    <span class="n">svm</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">5</span><span class="p">),</span> <span class="n">show_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">svm</span><span class="o">.</span><span class="n">generate_gif</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="svm-optimal-hyperparameters">
<h4>SVM optimal hyperparameters<a class="headerlink" href="#svm-optimal-hyperparameters" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm</span><span class="o">.</span><span class="n">optimal_hyperparams</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id6">
<h4>XG Boost Classification<a class="headerlink" href="#id6" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">27</span><span class="p">):</span>
    <span class="n">xgclas</span><span class="o">.</span><span class="n">classifier_predict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xgclas</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">xgclas</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
    <span class="n">xgclas</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">5</span><span class="p">),</span> <span class="n">show_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
<span class="n">xgclas</span><span class="o">.</span><span class="n">generate_gif</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgclas</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="xg-boost-classification-optimal-hyperparameters">
<h4>XG Boost Classification optimal hyperparameters<a class="headerlink" href="#xg-boost-classification-optimal-hyperparameters" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgclas</span><span class="o">.</span><span class="n">optimal_hyperparams</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id7">
<h4>XG Boost Regression<a class="headerlink" href="#id7" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">27</span><span class="p">):</span>
    <span class="n">xgreg</span><span class="o">.</span><span class="n">regressor_predict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xgreg</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">xgreg</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
    <span class="n">xgreg</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">5</span><span class="p">),</span> <span class="n">show_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
<span class="n">xgreg</span><span class="o">.</span><span class="n">generate_gif</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgreg</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="xg-boost-regression-optimal-hyperparameters">
<h4>XG Boost Regression optimal hyperparameters<a class="headerlink" href="#xg-boost-regression-optimal-hyperparameters" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgreg</span><span class="o">.</span><span class="n">optimal_hyperparams</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id8">
<h4>ElasticNet Regression<a class="headerlink" href="#id8" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">27</span><span class="p">):</span>
    <span class="n">elas</span><span class="o">.</span><span class="n">regressor_predict</span><span class="p">()</span>
    <span class="n">elas</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">elas</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
    <span class="n">elas</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">5</span><span class="p">),</span> <span class="n">show_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
<span class="n">elas</span><span class="o">.</span><span class="n">generate_gif</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elas</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="elasticnet-optimal-hyperparameters">
<h4>ElasticNet optimal hyperparameters<a class="headerlink" href="#elasticnet-optimal-hyperparameters" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elas</span><span class="o">.</span><span class="n">optimal_hyperparams</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="q1-discussion-interpretation">
<h3>Q1: Discussion &amp; Interpretation<a class="headerlink" href="#q1-discussion-interpretation" title="Link to this heading">#</a></h3>
<p>Before optimizing the objective model the loss surface is unknown. The real loss surface, in our case, is the same as running a 40x40 grid search over all hyperparameter configurations. However, the computations will be very expensive to run. It order to save on computation cost we apply Bayesian optimization. Bayesian optimization prevents you from searching in locations were the loss is expected to be bad and will probably not improve. This is in stark contrast to grid search, where you need to check every possible hyperparameter conbination. The difference with random search is that random search does not place a prior on the loss function.</p>
<p>The more complex the loss surface, the longer it will take the Bayesian optimization to find the best hyperparameters. It will need to conduct more exploration to find possible improvements, before it can exploit. As we can see in the surrogate-loss graphs SVM has a more complex loss function than the other models, this results in the optimizer finding better hyperparameter combinations as it explores and exploits. (You can see this effect in the iterations-loss graph)</p>
<p>Especially for simple loss surfaces an optimal hyperparameter setting can be found among the first 10 random samples. Imagine a flat surface (hyperparameters have no influence on the loss), after one random sample you will have found the optimal hyperparameters (you do not need to explore). For the other models we observe a simpler surface then for SVM and therefore there is not much change in the minimum loss (After the initial 10 samples).</p>
<p>The efficiency of Bayesian optimization will become more apparent when increasing the amount of hyperparameters to tune. Adding a parameter to your grid search will add an entire additional dimension to the search space. However, with Bayesian optimization you might only need to run it for a few more iterations, depending on the interaction between hyperparameters.</p>
<p>The efficiency of Bayesian optimization is also better when you have a model that needs a lot of tuning to achieve better results. As you can see all models except SVM already perform good out of the box. This means our optimization will not improve our models much.</p>
<p>Our conclusion is that Bayesian optimization is not that effective in our situation, since for almost every model the optimal hyperparameters were found in the initial 10 random samples. However, when increasing the amount of hyperparameters to tune, Bayesian optimization will become more efficient.</p>
<p>(Bayesian optimization works well for both classification and regression, resulting in us not noticing any big differences between the two datasets.)</p>
<section id="note">
<h4>Note<a class="headerlink" href="#note" title="Link to this heading">#</a></h4>
<p>We decided not to plot the uncertainty interval as it made our plots convoluted and a bit difficult to grasp.</p>
</section>
</section>
</section>
<hr class="docutils" />
<section id="warm-starting-bayesian-optimization-20-points">
<h2>2. Warm-starting Bayesian Optimization (20 points) {-}<a class="headerlink" href="#warm-starting-bayesian-optimization-20-points" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Oh no! 6 of the sensors in the first dataset (robot navigation) suddenly broke. You need to quickly retrain the model but
there is no time for a complete re-optimization.</p></li>
<li><p>Revisit question 1, but additionally keep a list of the 10 best hyperparameter configurations while you run Bayesian optimization.</p></li>
<li><p>Randomly remove 6 columns from the dataset (or remove them manually as long as they are not adjacent) to simulate the broken sensors.</p></li>
<li><p>Re-run the Bayesian optimization (only for the first dataset), but now start from the 10 best configurations (for each classifier) rather than 10
random ones.</p></li>
<li><p>Visualize the surrogate model (as before) at the initial state, and at 3 subsequent iterations.</p></li>
<li><p>Interpret and discuss the results. Did the warm-start help? Could you find a good model after a few iterations?
Explain the benefits of this approach over starting from scratch or using a random search.</p></li>
</ul>
<section id="best-hyperparameter-configurations">
<h3>10 best hyperparameter configurations<a class="headerlink" href="#best-hyperparameter-configurations" title="Link to this heading">#</a></h3>
<section id="id9">
<h4>SVM Classification<a class="headerlink" href="#id9" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># get 10 best hyperparameter configurations from question 1</span>
<span class="n">svm_best_params</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">optimal_hyperparams</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">svm_best_params</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># set loss to none</span>
<span class="n">svm_best_params</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">svm_best_params</span>
</pre></div>
</div>
</div>
</div>
<section id="id10">
<h5>XG Boost Classification<a class="headerlink" href="#id10" title="Link to this heading">#</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># get 10 best hyperparameter configurations from question 1</span>
<span class="n">xgclas_best_params</span> <span class="o">=</span> <span class="n">xgclas</span><span class="o">.</span><span class="n">optimal_hyperparams</span><span class="p">(</span><span class="n">rows</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">xgclas_best_params</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># set loss to none</span>
<span class="n">xgclas_best_params</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">xgclas_best_params</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="randomly-remove-6-columns-from-the-dataset">
<h4>Randomly remove 6 columns from the dataset<a class="headerlink" href="#randomly-remove-6-columns-from-the-dataset" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set seed for reproducability</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Randomly remove 6 columns, i.e., randomly pick 18 columns to keep </span>
<span class="n">kept_columns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">23</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">X_broken</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">kept_columns</span><span class="p">]</span>
<span class="n">X_broken</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="re-run-the-bayesian-optimization-starting-from-the-10-best-configurations-and-visualize-surrogate-model-at-initial-state">
<h4>Re-run the Bayesian optimization, starting from the 10 best configurations and visualize surrogate model at initial state<a class="headerlink" href="#re-run-the-bayesian-optimization-starting-from-the-10-best-configurations-and-visualize-surrogate-model-at-initial-state" title="Link to this heading">#</a></h4>
<section id="id11">
<h5>SVM Classification<a class="headerlink" href="#id11" title="Link to this heading">#</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm_broken</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
    <span class="n">surrogate_model</span><span class="o">=</span><span class="n">ProbRandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">objective_model</span><span class="o">=</span><span class="n">SVC</span><span class="p">,</span>
    <span class="n">acquisition_function</span><span class="o">=</span><span class="n">EI</span><span class="p">,</span>
    <span class="n">hyperparam_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;C&#39;</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">),</span>
    <span class="n">hyperparam_space</span><span class="o">=</span><span class="n">svm_param_template</span><span class="p">,</span>
    <span class="n">X_obj</span><span class="o">=</span><span class="n">X_broken</span><span class="p">,</span>
    <span class="n">y_obj</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="n">svm_broken</span><span class="o">.</span><span class="n">hyperparams_obj</span> <span class="o">=</span> <span class="n">svm_best_params</span>
<span class="n">svm_broken</span><span class="o">.</span><span class="n">hyperparam_cartesian</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="n">svm_broken</span><span class="o">.</span><span class="n">classifier_predict</span><span class="p">()</span>
<span class="n">svm_broken</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>

<span class="n">svm_broken</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(10 Samples)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id12">
<h5>XG Boost Classification<a class="headerlink" href="#id12" title="Link to this heading">#</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgclas_broken</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
    <span class="n">surrogate_model</span><span class="o">=</span><span class="n">ProbRandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">objective_model</span><span class="o">=</span><span class="n">XGBClassifier</span><span class="p">,</span>
    <span class="n">acquisition_function</span><span class="o">=</span><span class="n">EI</span><span class="p">,</span>
    <span class="n">hyperparam_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">),</span>
    <span class="n">hyperparam_space</span><span class="o">=</span><span class="n">xgclas_param_template</span><span class="p">,</span>
    <span class="n">X_obj</span><span class="o">=</span><span class="n">X_broken</span><span class="p">,</span>
    <span class="n">y_obj</span><span class="o">=</span><span class="n">y</span>
<span class="p">)</span>

<span class="n">xgclas_broken</span><span class="o">.</span><span class="n">hyperparams_obj</span> <span class="o">=</span> <span class="n">xgclas_best_params</span>
<span class="n">xgclas_broken</span><span class="o">.</span><span class="n">hyperparam_cartesian</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="n">xgclas_broken</span><span class="o">.</span><span class="n">classifier_predict</span><span class="p">()</span>
<span class="n">xgclas_broken</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>

<span class="n">xgclas_broken</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;(10 Samples)&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="visualize-the-surrogate-model-at-3-subsequent-iterations">
<h4>Visualize the surrogate model at 3 subsequent iterations<a class="headerlink" href="#visualize-the-surrogate-model-at-3-subsequent-iterations" title="Link to this heading">#</a></h4>
<section id="id13">
<h5>SVM Classification<a class="headerlink" href="#id13" title="Link to this heading">#</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm_broken</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">svm_broken</span><span class="o">.</span><span class="n">classifier_predict</span><span class="p">()</span>
    <span class="n">svm_broken</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">svm_broken</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">svm_broken</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="svm-warm-start-optimal-hyperparameters">
<h4>SVM warm-start optimal hyperparameters<a class="headerlink" href="#svm-warm-start-optimal-hyperparameters" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svm_broken</span><span class="o">.</span><span class="n">optimal_hyperparams</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="id14">
<h5>XG Boost Classification<a class="headerlink" href="#id14" title="Link to this heading">#</a></h5>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgclas_broken</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">xgclas_broken</span><span class="o">.</span><span class="n">classifier_predict</span><span class="p">()</span>
    <span class="n">xgclas_broken</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">xgclas_broken</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">xgclas_broken</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="xg-boost-classification-warm-start-optimal-hyperparameters">
<h4>XG Boost classification warm-start optimal hyperparameters<a class="headerlink" href="#xg-boost-classification-warm-start-optimal-hyperparameters" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgclas_broken</span><span class="o">.</span><span class="n">optimal_hyperparams</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="q2-discussion-interpretation">
<h3>Q2: Discussion &amp; Interpretation<a class="headerlink" href="#q2-discussion-interpretation" title="Link to this heading">#</a></h3>
<p>The warm start did help with finding a good model in few iterations. From the plots of the XG Boost Classification model, you can see that expected improvement dropped rapidly after only a few iterations, with a low loss and expected improvement after the third iteration. From the plots of the SVM model, we do not observe this phenomenon. We expect that the surrogate model is still adjusting to the new data with six broken columns for the first few iterations. Hence, uncertainty is high and therefore we can see a high expected improvement.</p>
<p>The benefits of a warm-start approach over starting from scratch or using a random search are related to the concepts of exploitation versus exploration. Acquisition functions trade off exploitation and exploration, where exploitation means sampling where the surrogate model predicts a low objective loss and exploration means sampling at locations where uncertainty is high. Better initial hyperparameter values, i.e., warm start, encourage Bayesian optimization to prevent exploration and focus on exploitation, hereby finding a good model after fewer iterations.</p>
</section>
</section>
<section id="gaussian-processes-20-points">
<h2>3. Gaussian Processes (20 points) {-}<a class="headerlink" href="#gaussian-processes-20-points" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Replace the probabilistic Random Forest used above with a Gaussian Process.</p></li>
<li><p>Repeat the Bayesian Optimization for one of the datasets, again visualizing the surrogate model and the acquisition function.</p></li>
<li><p>If the surrogate models do not look right, do manual tuning</p></li>
</ul>
<ul class="simple">
<li><p>Hint: Try <code class="docutils literal notranslate"><span class="pre">y_normalize</span></code>, regularizing the <code class="docutils literal notranslate"><span class="pre">alpha</span></code> hyperparameter, or trying a different kernel.</p></li>
</ul>
<ul class="simple">
<li><p>Interpret and discuss the results. In which ways are the Gaussian Processes better or worse? Consider both accuracy, speed of finding a good configuration, and runtime. Interpret and explain the results as well as you can.</p></li>
</ul>
<section id="guassian-process-with-xgbregressor">
<h3>Guassian Process with XGBRegressor<a class="headerlink" href="#guassian-process-with-xgbregressor" title="Link to this heading">#</a></h3>
<section id="visualize-10-random-samples">
<h4>Visualize 10 random samples<a class="headerlink" href="#visualize-10-random-samples" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpr</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">normalize_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>

<span class="n">xgreg_gp</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
  <span class="n">surrogate_model</span><span class="o">=</span><span class="n">gpr</span><span class="p">,</span>
  <span class="n">objective_model</span><span class="o">=</span><span class="n">XGBRegressor</span><span class="p">,</span>
  <span class="n">acquisition_function</span><span class="o">=</span><span class="n">EI</span><span class="p">,</span>
  <span class="n">hyperparam_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">,</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">),</span>
  <span class="n">hyperparam_space</span><span class="o">=</span><span class="n">xgreg_param_template</span><span class="p">,</span>
  <span class="n">X_obj</span><span class="o">=</span><span class="n">Xr</span><span class="p">,</span>
  <span class="n">y_obj</span><span class="o">=</span><span class="n">yr</span>
<span class="p">)</span>

<span class="n">xgreg_gp</span><span class="o">.</span><span class="n">hyperparam_sampling</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">xgreg_gp</span><span class="o">.</span><span class="n">hyperparam_cartesian</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="n">xgreg_gp</span><span class="o">.</span><span class="n">regressor_predict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">xgreg_gp</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>

<span class="n">xgreg_gp</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;(10 Samples)&#39;</span><span class="p">,</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="id15">
<h3>Visualize 3 iterations<a class="headerlink" href="#id15" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgreg_gp</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">xgreg_gp</span><span class="o">.</span><span class="n">regressor_predict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xgreg_gp</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">xgreg_gp</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">2</span><span class="p">),</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">xgreg_gp</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-30-iterations-with-a-gif">
<h3>Visualize 30 iterations with a GIF<a class="headerlink" href="#visualize-30-iterations-with-a-gif" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">27</span><span class="p">):</span>
    <span class="n">xgreg_gp</span><span class="o">.</span><span class="n">regressor_predict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xgreg_gp</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">xgreg_gp</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
    <span class="n">xgreg_gp</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">5</span><span class="p">),</span> <span class="n">show_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
<span class="n">xgreg_gp</span><span class="o">.</span><span class="n">generate_gif</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="plot-the-minimum-loss-over-30-iterations-with-xgbregressor-as-objective-model">
<h4>Plot the minimum loss over 30 iterations with XGBRegressor as objective model<a class="headerlink" href="#plot-the-minimum-loss-over-30-iterations-with-xgbregressor-as-objective-model" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xgreg</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">()</span>
<span class="n">xgreg_gp</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="runtime-comparison-with-different-surrogate-models-for-xgbregressor-as-objective-model">
<h4>Runtime comparison with different surrogate models for XGBRegressor as objective model<a class="headerlink" href="#runtime-comparison-with-different-surrogate-models-for-xgbregressor-as-objective-model" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compare_time_sur</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">model2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compares running time of different surrogate models</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">model1</span><span class="o">.</span><span class="n">time_surrogate</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">model1</span><span class="o">.</span><span class="n">time_surrogate</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="nb">type</span><span class="p">(</span><span class="n">model1</span><span class="o">.</span><span class="n">surrogate_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">time_surrogate</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">model2</span><span class="o">.</span><span class="n">time_surrogate</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="nb">type</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">surrogate_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Comparison surrogate model runtime of </span><span class="si">{}</span><span class="s1"> vs </span><span class="si">{}</span><span class="s1"> for objective model </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span>
              <span class="nb">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">model1</span><span class="o">.</span><span class="n">surrogate_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> 
                     <span class="nb">type</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">surrogate_model</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                     <span class="n">model1</span><span class="o">.</span><span class="n">model_name</span><span class="p">),</span>
             <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;iteration nr&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;runtime (s)&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compare_time_sur</span><span class="p">(</span><span class="n">xgreg</span><span class="p">,</span> <span class="n">xgreg_gp</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="compare-optimal-hyperparameters-for-xgbregressor-with-gaussianprocessregressor-vs-probrandomforestregressor">
<h4>Compare optimal hyperparameters for XGBRegressor with GaussianProcessRegressor vs ProbRandomForestRegressor<a class="headerlink" href="#compare-optimal-hyperparameters-for-xgbregressor-with-gaussianprocessregressor-vs-probrandomforestregressor" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimal hyperparameters for </span><span class="si">{}</span><span class="s1"> with </span><span class="si">{}</span><span class="s1"> as surrogate&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xgreg</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span> <span class="n">xgreg</span><span class="o">.</span><span class="n">surrogate_model_name</span><span class="p">))</span>
<span class="n">xgreg</span><span class="o">.</span><span class="n">optimal_hyperparams</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimal hyperparameters for </span><span class="si">{}</span><span class="s1"> with </span><span class="si">{}</span><span class="s1"> as surrogate&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xgreg_gp</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span> <span class="n">xgreg_gp</span><span class="o">.</span><span class="n">surrogate_model_name</span><span class="p">))</span>
<span class="n">xgreg_gp</span><span class="o">.</span><span class="n">optimal_hyperparams</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="guassian-process-with-elasticnet-regression">
<h3>Guassian Process with ElasticNet Regression<a class="headerlink" href="#guassian-process-with-elasticnet-regression" title="Link to this heading">#</a></h3>
</section>
<section id="id16">
<h3>Visualize 10 random samples<a class="headerlink" href="#id16" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gpr</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">normalize_y</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>

<span class="n">elas_gpr</span> <span class="o">=</span> <span class="n">BayesianOptimization</span><span class="p">(</span>
  <span class="n">surrogate_model</span><span class="o">=</span><span class="n">gpr</span><span class="p">,</span>
  <span class="n">objective_model</span><span class="o">=</span><span class="n">ElasticNet</span><span class="p">,</span>
  <span class="n">acquisition_function</span><span class="o">=</span><span class="n">EI</span><span class="p">,</span>
  <span class="n">hyperparam_names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;alpha&#39;</span><span class="p">,</span> <span class="s1">&#39;l1_ratio&#39;</span><span class="p">),</span>
  <span class="n">hyperparam_space</span><span class="o">=</span><span class="n">elas_param_template</span><span class="p">,</span>
  <span class="n">X_obj</span><span class="o">=</span><span class="n">Xr</span><span class="p">,</span>
  <span class="n">y_obj</span><span class="o">=</span><span class="n">yr</span>
<span class="p">)</span>

<span class="n">elas_gpr</span><span class="o">.</span><span class="n">hyperparam_sampling</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">elas_gpr</span><span class="o">.</span><span class="n">hyperparam_cartesian</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="n">elas_gpr</span><span class="o">.</span><span class="n">regressor_predict</span><span class="p">()</span>
<span class="n">elas_gpr</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>

<span class="n">elas_gpr</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;(10 Samples)&#39;</span><span class="p">,</span> <span class="n">store_plot</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id17">
<h3>Visualize 3 iterations<a class="headerlink" href="#id17" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elas_gpr</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">elas_gpr</span><span class="o">.</span><span class="n">regressor_predict</span><span class="p">()</span>
    <span class="n">elas_gpr</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">elas_gpr</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">2</span><span class="p">),</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">elas_gpr</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-30-iterations-with-gif">
<h3>Visualize 30 iterations with GIF<a class="headerlink" href="#visualize-30-iterations-with-gif" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">27</span><span class="p">):</span>
    <span class="n">elas_gpr</span><span class="o">.</span><span class="n">regressor_predict</span><span class="p">()</span>
    <span class="n">elas_gpr</span><span class="o">.</span><span class="n">surrogate_predict</span><span class="p">()</span>
    <span class="n">elas_gpr</span><span class="o">.</span><span class="n">next_sample</span><span class="p">()</span>
    <span class="n">elas_gpr</span><span class="o">.</span><span class="n">plot_surrogate</span><span class="p">(</span><span class="s1">&#39;(Iteration </span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">idx</span><span class="o">+</span><span class="mi">5</span><span class="p">),</span> <span class="n">show_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">store_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
<span class="n">elas_gpr</span><span class="o">.</span><span class="n">generate_gif</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="compare-loss-xgboost-regression-rfr-gp">
<h4>Compare loss xgboost regression RFR &amp; GP<a class="headerlink" href="#compare-loss-xgboost-regression-rfr-gp" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">elas</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">()</span>
<span class="n">elas_gpr</span><span class="o">.</span><span class="n">plot_loss</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="compare-times-xgboost-regression-rfr-gp">
<h4>Compare times xgboost regression RFR &amp; GP<a class="headerlink" href="#compare-times-xgboost-regression-rfr-gp" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compare_time_sur</span><span class="p">(</span><span class="n">elas</span><span class="p">,</span> <span class="n">elas_gpr</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="compare-optimal-hyperparameters-for-elasticnet-with-gaussianprocessregressor-vs-probrandomforestregressor">
<h4>Compare optimal hyperparameters for ElasticNet with GaussianProcessRegressor vs ProbRandomForestRegressor<a class="headerlink" href="#compare-optimal-hyperparameters-for-elasticnet-with-gaussianprocessregressor-vs-probrandomforestregressor" title="Link to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimal hyperparameters for </span><span class="si">{}</span><span class="s1"> with </span><span class="si">{}</span><span class="s1"> as surrogate&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">elas</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span> <span class="n">elas</span><span class="o">.</span><span class="n">surrogate_model_name</span><span class="p">))</span>
<span class="n">elas</span><span class="o">.</span><span class="n">optimal_hyperparams</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Optimal hyperparameters for </span><span class="si">{}</span><span class="s1"> with </span><span class="si">{}</span><span class="s1"> as surrogate&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">elas_gpr</span><span class="o">.</span><span class="n">model_name</span><span class="p">,</span> <span class="n">elas_gpr</span><span class="o">.</span><span class="n">surrogate_model_name</span><span class="p">))</span>
<span class="n">elas_gpr</span><span class="o">.</span><span class="n">optimal_hyperparams</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="q3-discussion-interpretation">
<h3>Q3: Discussion &amp; Interpretation<a class="headerlink" href="#q3-discussion-interpretation" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Tuning the GaussianProcessRegressor:</p>
<ul>
<li><p><strong>y-norm</strong>: Did not visibly affect the surface or performance of the surrogate model in this particular situation. Scikit learn suggests to set y-norm to True if the target values’ mean is expected to differ considerable from zero.</p></li>
<li><p><strong>alpha</strong>: Alpha is the regularization parameter and had clear effect on performance of the surrogate model. For the XGBRegressor the default value of alpha (1e-10) led to an error in the code. The Scikit learn documentation suggests this could be the result of numerical issues during the fitting process. With alpha = 1e-3, the surface of the surrogate model behaved as expected.</p></li>
<li><p><strong>n_restarts_optimizer</strong>: Again, did not seem to have an effect on the performance of the surrogate model in this particular situation.</p></li>
<li><p><strong>kernel</strong>: Highly affected the performance of the surrogate model. Default kernel was used this situation as it resulted in a nice surface.</p></li>
</ul>
</li>
<li><p>First of all, it immediately stands out that the different surrogate models behave quite differently. This is particularly true in the first scenario where XGBRegressor is the objective model. Here, the ProbRandomForestRegressor (PRFR) results in a blocky, slide-looking surface for which the max_depth hyperparameter seems to have little influence on the loss. In contrast, the GaussianProcessRegressor (GPR) is a smooth, wavy-looking surface where both hyperparameters clearly affect the loss. Despite the different surfaces, both surrogate models result in similar values for the optimal hyperparameters. Hence the type of surrogate model does not seem to be an important factor for overall accuracy for this dataset.</p></li>
<li><p>We can draw a similar conclusion looking at the plot that tracks the minimum observed loss over all the iterations of the bayesian optimization process. While there might be a minor improvement over the 30 iterations, generally all surrogate models tend to find a near optimal configuration with just 10 initial random samples. Note the small scale for the y-axis of the minimum loss graphs, this makes an improvement look deceptively large even though it only represents a small change.</p></li>
<li><p>Lastly, there is only a marginal difference in the runtime between PRFR and GPR as can be seen in the plots above. The runtime reflects the time it takes each iteration to fit the surrogate model and to make predictions on the given sample. Particularly in contrast to the running times of the objective models, both surrogate models are much more efficient in locating an ideal hyperparameter configuration.</p></li>
<li><p>Overall we can conclude that PRFR and GPR are equally as good in terms of surrogate models. The only noticable distinction between the two is that GPR requires more manual tuning and has smoother output surfaces.</p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./xtra/studies"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#robot-navigation">Robot Navigation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-the-data">Visualizing the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-models">Classification models</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#helper-functions">Helper functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-data">Load the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementing-bayesian-optimization-60-points">1. Implementing Bayesian Optimization (60 points) {-}</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#class-to-perform-the-bayesian-optimization">Class to perform the Bayesian Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#random-samples">10 random samples</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#svm-classification">SVM Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#xg-boost-classification">XG Boost Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#xg-boost-regression">XG Boost Regression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#elasticnet-regression">ElasticNet Regression</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-3-iterations">Visualize 3 iterations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">SVM Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">XG Boost Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id3">XG Boost Regression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id4">ElasticNet Regression</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#iterations">30 Iterations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id5">SVM Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#svm-optimal-hyperparameters">SVM optimal hyperparameters</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id6">XG Boost Classification</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#xg-boost-classification-optimal-hyperparameters">XG Boost Classification optimal hyperparameters</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id7">XG Boost Regression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#xg-boost-regression-optimal-hyperparameters">XG Boost Regression optimal hyperparameters</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id8">ElasticNet Regression</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#elasticnet-optimal-hyperparameters">ElasticNet optimal hyperparameters</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q1-discussion-interpretation">Q1: Discussion &amp; Interpretation</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#note">Note</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#warm-starting-bayesian-optimization-20-points">2. Warm-starting Bayesian Optimization (20 points) {-}</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#best-hyperparameter-configurations">10 best hyperparameter configurations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">SVM Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">XG Boost Classification</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#randomly-remove-6-columns-from-the-dataset">Randomly remove 6 columns from the dataset</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#re-run-the-bayesian-optimization-starting-from-the-10-best-configurations-and-visualize-surrogate-model-at-initial-state">Re-run the Bayesian optimization, starting from the 10 best configurations and visualize surrogate model at initial state</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id11">SVM Classification</a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id12">XG Boost Classification</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-surrogate-model-at-3-subsequent-iterations">Visualize the surrogate model at 3 subsequent iterations</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id13">SVM Classification</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#svm-warm-start-optimal-hyperparameters">SVM warm-start optimal hyperparameters</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#id14">XG Boost Classification</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#xg-boost-classification-warm-start-optimal-hyperparameters">XG Boost classification warm-start optimal hyperparameters</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q2-discussion-interpretation">Q2: Discussion &amp; Interpretation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-processes-20-points">3. Gaussian Processes (20 points) {-}</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#guassian-process-with-xgbregressor">Guassian Process with XGBRegressor</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-10-random-samples">Visualize 10 random samples</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id15">Visualize 3 iterations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-30-iterations-with-a-gif">Visualize 30 iterations with a GIF</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-minimum-loss-over-30-iterations-with-xgbregressor-as-objective-model">Plot the minimum loss over 30 iterations with XGBRegressor as objective model</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#runtime-comparison-with-different-surrogate-models-for-xgbregressor-as-objective-model">Runtime comparison with different surrogate models for XGBRegressor as objective model</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-optimal-hyperparameters-for-xgbregressor-with-gaussianprocessregressor-vs-probrandomforestregressor">Compare optimal hyperparameters for XGBRegressor with GaussianProcessRegressor vs ProbRandomForestRegressor</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#guassian-process-with-elasticnet-regression">Guassian Process with ElasticNet Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id16">Visualize 10 random samples</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id17">Visualize 3 iterations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-30-iterations-with-gif">Visualize 30 iterations with GIF</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-loss-xgboost-regression-rfr-gp">Compare loss xgboost regression RFR &amp; GP</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-times-xgboost-regression-rfr-gp">Compare times xgboost regression RFR &amp; GP</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-optimal-hyperparameters-for-elasticnet-with-gaussianprocessregressor-vs-probrandomforestregressor">Compare optimal hyperparameters for ElasticNet with GaussianProcessRegressor vs ProbRandomForestRegressor</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#q3-discussion-interpretation">Q3: Discussion &amp; Interpretation</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Joaquin Vanschoren
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023. CC0 Licensed - Use as you like. Appropriate credit is very welcome.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>